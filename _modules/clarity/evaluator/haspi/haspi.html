<!DOCTYPE html>

<html lang="en" data-content_root="../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>clarity.evaluator.haspi.haspi &#8212; Project name not set  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css?v=12dfc556" />
    <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="https://unpkg.com/mermaid@10.2.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for clarity.evaluator.haspi.haspi</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;HASPI intelligibility Index&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Final</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">clarity.evaluator.haspi.eb</span> <span class="kn">import</span> <span class="n">ear_model</span>
<span class="kn">from</span> <span class="nn">clarity.evaluator.haspi.ebm</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">cepstral_correlation_coef</span><span class="p">,</span>
    <span class="n">env_filter</span><span class="p">,</span>
    <span class="n">fir_modulation_filter</span><span class="p">,</span>
    <span class="n">modulation_cross_correlation</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">clarity.evaluator.haspi.ip</span> <span class="kn">import</span> <span class="n">get_neural_net</span><span class="p">,</span> <span class="n">nn_feed_forward_ensemble</span>
<span class="kn">from</span> <span class="nn">clarity.utils.audiogram</span> <span class="kn">import</span> <span class="n">Audiogram</span><span class="p">,</span> <span class="n">Listener</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">ndarray</span>


<span class="c1"># HASPI assumes the following audiogram frequencies:</span>
<span class="n">HASPI_AUDIOGRAM_FREQUENCIES</span><span class="p">:</span> <span class="n">Final</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">4000</span><span class="p">,</span> <span class="mi">6000</span><span class="p">])</span>


<div class="viewcode-block" id="haspi_v2">
<a class="viewcode-back" href="../../../../clarity.evaluator.haspi.haspi.html#clarity.evaluator.haspi.haspi_v2">[docs]</a>
<span class="k">def</span> <span class="nf">haspi_v2</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments too-many-locals</span>
    <span class="n">reference</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">reference_sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">processed</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">processed_sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">audiogram</span><span class="p">:</span> <span class="n">Audiogram</span><span class="p">,</span>
    <span class="n">level1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">65.0</span><span class="p">,</span>
    <span class="n">f_lp</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">320.0</span><span class="p">,</span>
    <span class="n">itype</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the HASPI intelligibility index using the</span>
<span class="sd">    auditory model followed by computing the envelope cepstral</span>
<span class="sd">    correlation and BM vibration high-level covariance. The reference</span>
<span class="sd">    signal presentation level for NH listeners is assumed to be 65 dB</span>
<span class="sd">    SPL. The same model is used for both normal and impaired hearing. This</span>
<span class="sd">    version of HASPI uses a modulation filterbank followed by an ensemble of</span>
<span class="sd">    neural networks to compute the estimated intelligibility.</span>

<span class="sd">    **NB** - The original HASPI model derivation included a bug which meant that</span>
<span class="sd">    although the &#39;shift&#39; parameter used in band centre frequency calculations was set to</span>
<span class="sd">    &#39;0.02&#39; it was never actually applied. To replicate this behaviour ear_model is</span>
<span class="sd">    called with &#39;shift&#39; set to None.  For discussion please refer to the discussion in</span>
<span class="sd">    `Issue #105 &lt;https://github.com/claritychallenge/clarity/issues/105&gt;`</span>
<span class="sd">    for further details.</span>

<span class="sd">    Args:</span>
<span class="sd">        reference (np.ndarray): Clear input reference speech signal with no noise or</span>
<span class="sd">            distortion. If a hearing loss is specified, no amplification should be</span>
<span class="sd">            provided.</span>
<span class="sd">        reference_sample_rate (int): Sampling rate in Hz for signal x</span>
<span class="sd">        processed (np.ndarray): Output signal with noise, distortion, HA gain, and/or</span>
<span class="sd">            processing.</span>
<span class="sd">        processed_sample_rate (int): Sampling rate in Hz for signal y.</span>
<span class="sd">        hearing_loss (np.ndarray): (1,6) vector of hearing loss at the 6 audiometric</span>
<span class="sd">            frequencies [250, 500, 1000, 2000, 4000, 6000] Hz.</span>
<span class="sd">        level1 (int): Optional input specifying level in dB SPL that corresponds to a</span>
<span class="sd">            signal RMS = 1. Default is 65 dB SPL if argument not provided.</span>
<span class="sd">        f_lp (int):</span>
<span class="sd">        itype (int): Intelligibility model</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple(Intel: float, raw: nd-array)</span>
<span class="sd">        Intel: Intelligibility estimated by passing the cepstral coefficients</span>
<span class="sd">              through a modulation filterbank followed by an ensemble of</span>
<span class="sd">              neural networks.</span>
<span class="sd">        raw: vector of 10 cep corr modulation filterbank outputs, averaged</span>
<span class="sd">              over basis functions 2-6.</span>

<span class="sd">    Updates:</span>
<span class="sd">        James M. Kates, 5 August 2013.</span>
<span class="sd">        Translated from MATLAB to Python by Zuzanna Podwinska, March 2022.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">audiogram</span><span class="o">.</span><span class="n">has_frequencies</span><span class="p">(</span><span class="n">HASPI_AUDIOGRAM_FREQUENCIES</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Audiogram does not have all HASPI frequency measurements&quot;</span>
            <span class="s2">&quot;Measurements will be interpolated&quot;</span>
        <span class="p">)</span>

    <span class="c1"># Adjust audiogram to match the standard frequencies</span>
    <span class="n">audiogram</span> <span class="o">=</span> <span class="n">audiogram</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="n">HASPI_AUDIOGRAM_FREQUENCIES</span><span class="p">)</span>

    <span class="c1"># Auditory model for intelligibility</span>
    <span class="c1"># Reference is no processing, normal hearing</span>
    <span class="n">reference_env</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">processed_env</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fsamp</span> <span class="o">=</span> <span class="n">ear_model</span><span class="p">(</span>
        <span class="n">reference</span><span class="p">,</span>
        <span class="n">reference_sample_rate</span><span class="p">,</span>
        <span class="n">processed</span><span class="p">,</span>
        <span class="n">processed_sample_rate</span><span class="p">,</span>
        <span class="n">audiogram</span><span class="o">.</span><span class="n">levels</span><span class="p">,</span>
        <span class="n">itype</span><span class="p">,</span>
        <span class="n">level1</span><span class="p">,</span>
        <span class="c1"># shift=0.02 # See comment in docstring</span>
        <span class="n">shift</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Envelope modulation features</span>

    <span class="c1"># LP filter and subsample the envelope</span>
    <span class="n">fsub</span> <span class="o">=</span> <span class="mf">8.0</span> <span class="o">*</span> <span class="n">f_lp</span>  <span class="c1"># subsample to span 2 octaves above the cutoff frequency</span>
    <span class="n">reference_lp</span><span class="p">,</span> <span class="n">processed_lp</span> <span class="o">=</span> <span class="n">env_filter</span><span class="p">(</span>
        <span class="n">reference_env</span><span class="p">,</span> <span class="n">processed_env</span><span class="p">,</span> <span class="n">f_lp</span><span class="p">,</span> <span class="n">fsub</span><span class="p">,</span> <span class="n">fsamp</span>
    <span class="p">)</span>

    <span class="c1"># Compute the cepstral coefficients as a function of subsampled time</span>
    <span class="n">nbasis</span> <span class="o">=</span> <span class="mi">6</span>  <span class="c1"># Use 6 basis functions</span>
    <span class="n">thr</span> <span class="o">=</span> <span class="mf">2.5</span>  <span class="c1"># Silence threshold in dB SL</span>
    <span class="n">dither</span> <span class="o">=</span> <span class="mf">0.1</span>  <span class="c1"># Dither in dB RMS to add to envelope signals</span>
    <span class="n">reference_cep</span><span class="p">,</span> <span class="n">processed_cep</span> <span class="o">=</span> <span class="n">cepstral_correlation_coef</span><span class="p">(</span>
        <span class="n">reference_lp</span><span class="p">,</span> <span class="n">processed_lp</span><span class="p">,</span> <span class="n">thr</span><span class="p">,</span> <span class="n">dither</span><span class="p">,</span> <span class="n">nbasis</span>
    <span class="p">)</span>

    <span class="c1"># Cepstral coefficients filtered at each modulation rate</span>
    <span class="c1"># Band center frequencies [2, 6, 10, 16, 25, 40, 64, 100, 160, 256] Hz</span>
    <span class="c1"># Band edges [0, 4, 8, 12.5, 20.5, 30.5, 52.4, 78.1, 128, 200, 328] Hz</span>
    <span class="n">reference_mod</span><span class="p">,</span> <span class="n">processed_mod</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">fir_modulation_filter</span><span class="p">(</span>
        <span class="n">reference_cep</span><span class="p">,</span> <span class="n">processed_cep</span><span class="p">,</span> <span class="n">fsub</span>
    <span class="p">)</span>

    <span class="c1"># Cross-correlation between the cepstral coefficients for the degraded and</span>
    <span class="c1"># ref signals at each modulation rate, averaged over basis functions 2-6</span>
    <span class="n">average_correlation_matrix</span> <span class="o">=</span> <span class="n">modulation_cross_correlation</span><span class="p">(</span>
        <span class="n">reference_mod</span><span class="p">,</span> <span class="n">processed_mod</span>
    <span class="p">)</span>

    <span class="c1"># Intelligibility prediction</span>
    <span class="c1"># Get the neural network parameters and the weights for an ensemble of 10 networks</span>
    <span class="p">(</span>
        <span class="n">neural_net_params</span><span class="p">,</span>
        <span class="n">weights_hidden</span><span class="p">,</span>
        <span class="n">weights_out</span><span class="p">,</span>
        <span class="n">normalization_factor</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">get_neural_net</span><span class="p">()</span>

    <span class="c1"># Average the neural network outputs for the modulation filterbank values</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">nn_feed_forward_ensemble</span><span class="p">(</span>
        <span class="n">average_correlation_matrix</span><span class="p">,</span> <span class="n">neural_net_params</span><span class="p">,</span> <span class="n">weights_hidden</span><span class="p">,</span> <span class="n">weights_out</span>
    <span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">model</span> <span class="o">/</span> <span class="n">normalization_factor</span>

    <span class="c1"># Return the intelligibility estimate and raw modulation filter outputs</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">average_correlation_matrix</span></div>



<div class="viewcode-block" id="haspi_v2_be">
<a class="viewcode-back" href="../../../../clarity.evaluator.haspi.haspi.html#clarity.evaluator.haspi.haspi_v2_be">[docs]</a>
<span class="k">def</span> <span class="nf">haspi_v2_be</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">reference_left</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">reference_right</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">processed_left</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">processed_right</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">listener</span><span class="p">:</span> <span class="n">Listener</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">100.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Better ear HASPI.</span>

<span class="sd">    Calculates HASPI for left and right ear and selects the better result.</span>

<span class="sd">    Args:</span>
<span class="sd">        ref_left (np.ndarray): left channel of reference signal</span>
<span class="sd">        ref_right (np.ndarray): right channel of reference signal</span>
<span class="sd">        proc_left (np.ndarray): left channel of processed signal</span>
<span class="sd">        proc_right (np.ndarray): right channel of processed signal</span>
<span class="sd">        sample_rate (int): sampling rate for both signal</span>
<span class="sd">        audiogram_left (): left ear audiogram</span>
<span class="sd">        audiogram_right (): right ear audiogram</span>
<span class="sd">        level: level in dB SPL corresponding to RMS=1</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: beHASPI score</span>

<span class="sd">    Updates:</span>
<span class="sd">        Zuzanna Podwinska, March 2022</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">score_left</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">haspi_v2</span><span class="p">(</span>
        <span class="n">reference_left</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">processed_left</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">listener</span><span class="o">.</span><span class="n">audiogram_left</span><span class="p">,</span>
        <span class="n">level</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">score_right</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">haspi_v2</span><span class="p">(</span>
        <span class="n">reference_right</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">processed_right</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">listener</span><span class="o">.</span><span class="n">audiogram_right</span><span class="p">,</span>
        <span class="n">level</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">score_left</span><span class="p">,</span> <span class="n">score_right</span><span class="p">)</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">Project name not set</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../recipes_doc.html">Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../CONTRIBUTING.html">Contributing to pyClarity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../clarity.html">clarity package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../recipes.html">recipes package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    

    
  </body>
</html>