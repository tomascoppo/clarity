<!DOCTYPE html>

<html lang="en" data-content_root="../../../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>clarity.evaluator.hasqi.hasqi &#8212; Project name not set  documentation</title>
    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=d1102ebc" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/alabaster.css?v=12dfc556" />
    <script src="../../../../_static/documentation_options.js?v=5929fcd5"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="https://unpkg.com/mermaid@10.2.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
   
  <link rel="stylesheet" href="../../../../_static/custom.css" type="text/css" />
  

  
  

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for clarity.evaluator.hasqi.hasqi</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">logging</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">TYPE_CHECKING</span><span class="p">,</span> <span class="n">Final</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="kn">from</span> <span class="nn">clarity.evaluator.haspi</span> <span class="kn">import</span> <span class="n">eb</span>
<span class="kn">from</span> <span class="nn">clarity.utils.audiogram</span> <span class="kn">import</span> <span class="n">Audiogram</span><span class="p">,</span> <span class="n">Listener</span>

<span class="k">if</span> <span class="n">TYPE_CHECKING</span><span class="p">:</span>
    <span class="kn">from</span> <span class="nn">numpy</span> <span class="kn">import</span> <span class="n">ndarray</span>


<span class="c1"># HASQI assumes the following audiogram frequencies:</span>
<span class="n">HASQI_AUDIOGRAM_FREQUENCIES</span><span class="p">:</span> <span class="n">Final</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">250</span><span class="p">,</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="mi">2000</span><span class="p">,</span> <span class="mi">4000</span><span class="p">,</span> <span class="mi">6000</span><span class="p">])</span>


<div class="viewcode-block" id="hasqi_v2">
<a class="viewcode-back" href="../../../../clarity.evaluator.hasqi.hasqi.html#clarity.evaluator.hasqi.hasqi_v2">[docs]</a>
<span class="k">def</span> <span class="nf">hasqi_v2</span><span class="p">(</span>
    <span class="n">reference</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">reference_sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">processed</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">processed_sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">audiogram</span><span class="p">:</span> <span class="n">Audiogram</span><span class="p">,</span>
    <span class="n">equalisation</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">level1</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">65.0</span><span class="p">,</span>
    <span class="n">silence_threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.5</span><span class="p">,</span>
    <span class="n">add_noise</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
    <span class="n">segment_covariance</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="nb">list</span><span class="p">[</span><span class="nb">float</span><span class="p">]]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to compute the HASQI version 2 quality index using the</span>
<span class="sd">    auditory model followed by computing the envelope cepstral</span>
<span class="sd">    correlation and BM vibration average short-time coherence signals.</span>
<span class="sd">    The reference signal presentation level for NH listeners is assumed</span>
<span class="sd">    to be 65 dB SPL. The same model is used for both normal and</span>
<span class="sd">    impaired hearing.</span>

<span class="sd">    Arguments:</span>
<span class="sd">        reference (np.ndarray): Clear input reference speech signal with no noise or</span>
<span class="sd">            distortion. If a hearing loss is specified, NAL-R equalization is optional</span>
<span class="sd">        reference_sample_Rate (int): Sampling rate in Hz for reference signal.</span>
<span class="sd">        processed (np.ndarray): Output signal with noise, distortion, HA gain, and/or</span>
<span class="sd">            processing.</span>
<span class="sd">        processed_sample_rate (int): Sampling rate in Hz for processed signal.</span>
<span class="sd">        hearing_loss (np.ndarray): vector of hearing loss at the 6 audiometric</span>
<span class="sd">            frequencies [250, 500, 1000, 2000, 4000, 6000] Hz.</span>
<span class="sd">        equalisation (int): Mode to use when equalising the reference signal:</span>
<span class="sd">                1 = no EQ has been provided, the function will add NAL-R</span>
<span class="sd">                2 = NAL-R EQ has already been added to the reference signal</span>
<span class="sd">        level1: Optional input specifying level in dB SPL that corresponds to a</span>
<span class="sd">              signal RMS = 1. Default is 65 dB SPL if argument not provided.</span>
<span class="sd">        silence_threshold (float): Silence threshold sum across bands, dB above audio</span>
<span class="sd">            threshold. Default: 2.5</span>
<span class="sd">        add_noise (float): Additive noise in dB SL to conditional cross-covariance.</span>
<span class="sd">            Default is 0.0</span>
<span class="sd">        segment_covariance (int): Segment size for the covariance calculation.</span>
<span class="sd">            Default is 16</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple(Combined, Nonlin, Linear, raw)</span>
<span class="sd">            Combined: Quality estimate is the product of the nonlinear and linear terms</span>
<span class="sd">            Nonlin: Nonlinear quality component = (cepstral corr)^2 x seg BM coherence</span>
<span class="sd">            Linear: Linear quality component = std of spectrum and spectrum slope</span>
<span class="sd">            raw: Vector of raw values = [CepCorr, BMsync5, Dloud, Dslope]</span>

<span class="sd">    James M. Kates, 5 August 2013.</span>
<span class="sd">    Translated from MATLAB to Python by Gerardo Roa Dabike, October 2022.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">audiogram</span><span class="o">.</span><span class="n">has_frequencies</span><span class="p">(</span><span class="n">HASQI_AUDIOGRAM_FREQUENCIES</span><span class="p">):</span>
        <span class="n">logging</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
            <span class="s2">&quot;Audiogram does not have all HASQI frequency measurements&quot;</span>
            <span class="s2">&quot;Measurements will be interpolated&quot;</span>
        <span class="p">)</span>

    <span class="n">audiogram</span> <span class="o">=</span> <span class="n">audiogram</span><span class="o">.</span><span class="n">resample</span><span class="p">(</span><span class="n">HASQI_AUDIOGRAM_FREQUENCIES</span><span class="p">)</span>

    <span class="c1"># Auditory model for quality</span>
    <span class="c1"># Reference is no processing or NAL-R, impaired hearing</span>
    <span class="p">(</span>
        <span class="n">reference_db</span><span class="p">,</span>
        <span class="n">reference_basilar_membrane</span><span class="p">,</span>
        <span class="n">processed_db</span><span class="p">,</span>
        <span class="n">processed_basilar_membrane</span><span class="p">,</span>
        <span class="n">reference_sl</span><span class="p">,</span>
        <span class="n">processed_sl</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">eb</span><span class="o">.</span><span class="n">ear_model</span><span class="p">(</span>
        <span class="n">reference</span><span class="p">,</span>
        <span class="n">reference_sample_rate</span><span class="p">,</span>
        <span class="n">processed</span><span class="p">,</span>
        <span class="n">processed_sample_rate</span><span class="p">,</span>
        <span class="n">audiogram</span><span class="o">.</span><span class="n">levels</span><span class="p">,</span>
        <span class="n">equalisation</span><span class="p">,</span>
        <span class="n">level1</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Envelope and long-term average spectral features</span>
    <span class="c1"># Smooth the envelope outputs: 125 Hz sub-sampling rate</span>
    <span class="n">reference_smooth</span> <span class="o">=</span> <span class="n">eb</span><span class="o">.</span><span class="n">env_smooth</span><span class="p">(</span><span class="n">reference_db</span><span class="p">,</span> <span class="n">segment_covariance</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>
    <span class="n">processed_smooth</span> <span class="o">=</span> <span class="n">eb</span><span class="o">.</span><span class="n">env_smooth</span><span class="p">(</span><span class="n">processed_db</span><span class="p">,</span> <span class="n">segment_covariance</span><span class="p">,</span> <span class="n">sample_rate</span><span class="p">)</span>

    <span class="c1"># Mel cepstrum correlation using smoothed envelopes</span>
    <span class="p">(</span>
        <span class="n">average_cepstral_correlation</span><span class="p">,</span>
        <span class="n">_individual_cepstral_correlations</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">eb</span><span class="o">.</span><span class="n">mel_cepstrum_correlation</span><span class="p">(</span>
        <span class="n">reference_smooth</span><span class="p">,</span> <span class="n">processed_smooth</span><span class="p">,</span> <span class="n">silence_threshold</span><span class="p">,</span> <span class="n">add_noise</span>
    <span class="p">)</span>

    <span class="c1"># Linear changes in the log-term spectra</span>
    <span class="c1"># dloud  vector: [sum abs diff, std dev diff, max diff] spectra</span>
    <span class="c1"># dnorm  vector: [sum abs diff, std dev diff, max diff] norm spectra</span>
    <span class="c1"># dslope vector: [sum abs diff, std dev diff, max diff] slope</span>
    <span class="n">d_loud_stats</span><span class="p">,</span> <span class="n">_d_norm_stats</span><span class="p">,</span> <span class="n">d_slope_stats</span> <span class="o">=</span> <span class="n">eb</span><span class="o">.</span><span class="n">spectrum_diff</span><span class="p">(</span>
        <span class="n">reference_sl</span><span class="p">,</span> <span class="n">processed_sl</span>
    <span class="p">)</span>

    <span class="c1"># Temporal fine structure correlation measurements</span>
    <span class="c1"># Compute the time-frequency segment covariances</span>
    <span class="p">(</span>
        <span class="n">signal_cross_covariance</span><span class="p">,</span>
        <span class="n">reference_mean_square</span><span class="p">,</span>
        <span class="n">_processed_mean_square</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">=</span> <span class="n">eb</span><span class="o">.</span><span class="n">bm_covary</span><span class="p">(</span>
        <span class="n">reference_basilar_membrane</span><span class="p">,</span>
        <span class="n">processed_basilar_membrane</span><span class="p">,</span>
        <span class="n">segment_covariance</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="c1"># Average signal segment cross-covariance</span>
    <span class="c1"># avecov=weighted ave of cross-covariances, using only data above threshold</span>
    <span class="c1"># syncov=ave cross-covariance with added IHC loss of synchronization at HF</span>
    <span class="n">silence_threshold</span> <span class="o">=</span> <span class="mf">2.5</span>  <span class="c1"># Threshold in dB SL for including time-freq tile</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">ihc_sync_covariance</span> <span class="o">=</span> <span class="n">eb</span><span class="o">.</span><span class="n">ave_covary2</span><span class="p">(</span>
        <span class="n">signal_cross_covariance</span><span class="p">,</span> <span class="n">reference_mean_square</span><span class="p">,</span> <span class="n">silence_threshold</span>
    <span class="p">)</span>
    <span class="n">basilar_membrane_sync5</span> <span class="o">=</span> <span class="n">ihc_sync_covariance</span><span class="p">[</span>
        <span class="mi">4</span>
    <span class="p">]</span>  <span class="c1"># Ave segment coherence with IHC loss of sync</span>

    <span class="c1"># Extract and normalize the spectral features</span>
    <span class="c1"># Dloud:std</span>
    <span class="n">d_loud</span> <span class="o">=</span> <span class="n">d_loud_stats</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="mf">2.5</span>  <span class="c1"># Loudness difference std</span>
    <span class="n">d_loud</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">d_loud</span>  <span class="c1"># 1=perfect, 0=bad</span>
    <span class="n">d_loud</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">d_loud</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="c1"># Dslope:std</span>
    <span class="n">d_slope</span> <span class="o">=</span> <span class="n">d_slope_stats</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Slope difference std</span>
    <span class="n">d_slope</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">d_slope</span>
    <span class="n">d_slope</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">d_slope</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span> <span class="mf">0.0</span><span class="p">)</span>

    <span class="c1"># Construct the models</span>
    <span class="c1"># Nonlinear model</span>
    <span class="n">non_linear</span> <span class="o">=</span> <span class="p">(</span>
        <span class="n">average_cepstral_correlation</span><span class="o">**</span><span class="mi">2</span>
    <span class="p">)</span> <span class="o">*</span> <span class="n">basilar_membrane_sync5</span>  <span class="c1"># Combined envelope and temporal fine structure</span>
    <span class="c1"># Linear model</span>
    <span class="n">linear</span> <span class="o">=</span> <span class="mf">0.579</span> <span class="o">*</span> <span class="n">d_loud</span> <span class="o">+</span> <span class="mf">0.421</span> <span class="o">*</span> <span class="n">d_slope</span>  <span class="c1"># Linear fit</span>

    <span class="c1"># Combined model</span>
    <span class="n">combined</span> <span class="o">=</span> <span class="n">non_linear</span> <span class="o">*</span> <span class="n">linear</span>  <span class="c1"># Product of nonlinear x linear</span>

    <span class="c1"># Raw data</span>
    <span class="n">raw</span> <span class="o">=</span> <span class="p">[</span><span class="n">average_cepstral_correlation</span><span class="p">,</span> <span class="n">basilar_membrane_sync5</span><span class="p">,</span> <span class="n">d_loud</span><span class="p">,</span> <span class="n">d_slope</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">combined</span><span class="p">,</span> <span class="n">non_linear</span><span class="p">,</span> <span class="n">linear</span><span class="p">,</span> <span class="n">raw</span></div>



<div class="viewcode-block" id="hasqi_v2_better_ear">
<a class="viewcode-back" href="../../../../clarity.evaluator.hasqi.hasqi.html#clarity.evaluator.hasqi.hasqi_v2_better_ear">[docs]</a>
<span class="k">def</span> <span class="nf">hasqi_v2_better_ear</span><span class="p">(</span>
    <span class="n">reference_left</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">reference_right</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">processed_left</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">processed_right</span><span class="p">:</span> <span class="n">ndarray</span><span class="p">,</span>
    <span class="n">sample_rate</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">listener</span><span class="p">:</span> <span class="n">Listener</span><span class="p">,</span>
    <span class="n">level</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">100.0</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Better ear HASQI.</span>

<span class="sd">    Calculates HASQI for left and right ear and selects the better result.</span>

<span class="sd">    Args:</span>
<span class="sd">        reference_left (np.ndarray): left channel of reference signal</span>
<span class="sd">        reference_right (np.ndarray): right channel of reference signal</span>
<span class="sd">        reference_left (np.ndarray): left channel of processed signal</span>
<span class="sd">        reference_right (np.ndarray): right channel of processed signal</span>
<span class="sd">        sample_rate: sampling rate for both signal</span>
<span class="sd">        audiogram_l: left ear audiogram</span>
<span class="sd">        audiogram_r: right ear audiogram</span>
<span class="sd">        level: level in dB SPL corresponding to RMS=1</span>
<span class="sd">        audiogram_freq: selected frequencies to use for audiogram</span>

<span class="sd">    Returns:</span>
<span class="sd">        float: beHASQI score</span>

<span class="sd">    Gerardo Roa Dabike, November 2022</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">score_left</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">hasqi_v2</span><span class="p">(</span>
        <span class="n">reference_left</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">processed_left</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">listener</span><span class="o">.</span><span class="n">audiogram_left</span><span class="p">,</span>
        <span class="n">equalisation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">level1</span><span class="o">=</span><span class="n">level</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">score_right</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">hasqi_v2</span><span class="p">(</span>
        <span class="n">reference_right</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">processed_right</span><span class="p">,</span>
        <span class="n">sample_rate</span><span class="p">,</span>
        <span class="n">listener</span><span class="o">.</span><span class="n">audiogram_right</span><span class="p">,</span>
        <span class="n">equalisation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">level1</span><span class="o">=</span><span class="n">level</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="nb">max</span><span class="p">(</span><span class="n">score_left</span><span class="p">,</span> <span class="n">score_right</span><span class="p">)</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="Main">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../../../index.html">Project name not set</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../recipes_doc.html">Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../CONTRIBUTING.html">Contributing to pyClarity</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../CODE_OF_CONDUCT.html">Contributor Covenant Code of Conduct</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../clarity.html">clarity package</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../recipes.html">recipes package</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../../../index.html">Documentation overview</a><ul>
  <li><a href="../../../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<search id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</search>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &#169;.
      
      |
      Powered by <a href="https://www.sphinx-doc.org/">Sphinx 7.4.7</a>
      &amp; <a href="https://alabaster.readthedocs.io">Alabaster 0.7.16</a>
      
    </div>

    

    
  </body>
</html>